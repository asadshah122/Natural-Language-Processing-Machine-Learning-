{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anaconda admin \"python -m spacy download en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import spacy\n",
    "import spacy\n",
    "\n",
    "# Create an instance of spacy and call it \"nlp\"\n",
    "nlp = spacy.load(\"en_core_web_sm\") # Loading english language shortest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = '\"Mr. O\\'Neill thinks that the boys\\' stories about Chile\\'s capital aren\\'t amusing.\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Mr. O'Neill thinks that the boys' stories about Chile's capital aren't amusing.\"\n"
     ]
    }
   ],
   "source": [
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an object of our instance\n",
    "doc_object = nlp(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      "Mr.\n",
      "O'Neill\n",
      "thinks\n",
      "that\n",
      "the\n",
      "boys\n",
      "'\n",
      "stories\n",
      "about\n",
      "Chile\n",
      "'s\n",
      "capital\n",
      "are\n",
      "n't\n",
      "amusing\n",
      ".\n",
      "\"\n"
     ]
    }
   ],
   "source": [
    "# Separating all the tokens from our instance\n",
    "for token in doc_object:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" PUNCT | Mr. PROPN | O'Neill PROPN | thinks VERB | that ADP | the DET | boys NOUN | ' PART | stories NOUN | about ADP | Chile PROPN | 's PART | capital NOUN | are VERB | n't ADV | amusing ADJ | . PUNCT | \" PUNCT | "
     ]
    }
   ],
   "source": [
    "# Breaking the sentence according to Parts of Speech(POS)\n",
    "for token in doc_object:\n",
    "    print(token.text, token.pos_, end=\" | \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"It is best to access our website from 9 a.m. to 1 p.m. every weekend. The address is www.mywebsite.ie.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It\n",
      "is\n",
      "best\n",
      "to\n",
      "access\n",
      "our\n",
      "website\n",
      "from\n",
      "9\n",
      "a.m.\n",
      "to\n",
      "1\n",
      "p.m.\n",
      "every\n",
      "weekend\n",
      ".\n",
      "The\n",
      "address\n",
      "is\n",
      "www.mywebsite.ie\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "# Create a doc_object\n",
    "doc_object = nlp(sentence)\n",
    "# Show tokens from the doc_object\n",
    "for token in doc_object:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"I live about 20km from here. Taxi will cost about £50.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "live\n",
      "about\n",
      "20\n",
      "km\n",
      "from\n",
      "here\n",
      ".\n",
      "Taxi\n",
      "will\n",
      "cost\n",
      "about\n",
      "£\n",
      "50\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "doc_object = nlp(sentence)\n",
    "for token in doc_object:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57853"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sparse matrix \n",
    "len(doc_object.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "really\n",
      "like\n",
      "working\n",
      "with\n",
      "words\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "doc_object = nlp(\"I really like working with words!\")\n",
    "\n",
    "# Print each token\n",
    "for token in doc_object:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the first token\n",
    "doc_object[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "like working with"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the tokens from 3 to 6\n",
    "doc_object[2:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "words!"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting last 2 tokens\n",
    "doc_object[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NER\n",
    "doc_object = nlp(\"Samsung in Ireland are pleased with their new folding screen that they released after a $9 million investment.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samsung | in | Ireland | are | pleased | with | their | new | folding | screen | that | they | released | after | a | $ | 9 | million | investment | . | "
     ]
    }
   ],
   "source": [
    "for token in doc_object:\n",
    "    print(token, end=\" | \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samsung 381 Companies, agencies, institutions, etc.\n",
      "Ireland 382 Countries, cities, states\n",
      "$9 million 391 Monetary values, including unit\n"
     ]
    }
   ],
   "source": [
    "# Show NER of doc_object\n",
    "for entity in doc_object.ents:\n",
    "    print(entity, entity.label, spacy.explain(entity.label_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
